# ê¸´ê¸‰ í•«í”½ìŠ¤ - ê°¤ëŸ­ì‹œ ë²„ì¦ˆ/ì•„ì´í° ì„¸ëŒ€ ì •ë³´ ì†ì‹¤ ë° íƒ€ì„ì•„ì›ƒ ë¬¸ì œ

## ğŸ”´ ë¬¸ì œ ìš”ì•½

ì…ë ¥: `ì‚¼ì„±ì „ì ê°¤ëŸ­ì‹œ ë²„ì¦ˆ3 í”„ë¡œ ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í°`
ê²°ê³¼: Hard Mappingì´ `ê°¤ëŸ­ì‹œ ë²„ì¦ˆ`ë¡œ ì¶•ì†Œ â†’ ì •ë³´ ì†ì‹¤ â†’ FastPath timeout + Playwright frame detach

## ê·¼ë³¸ ì›ì¸

1. **Hard Mapping ë¶€ë¶„ ë§¤ì¹­ ë¬¸ì œ**: `ë²„ì¦ˆ3 í”„ë¡œ` â†’ `ë²„ì¦ˆ`ë¡œ ì¶•ì†Œ
2. **ì¤‘ë³µ ì‹¤í–‰ ë¬¸ì œ**: ì¶•ì†Œëœ ê²°ê³¼ë¥¼ ë‹¤ì‹œ Hard Mappingì— íƒœì›€
3. **ê²€ìƒ‰ì–´ ê³¼ë‹¤ ì¶•ì†Œ**: `Samsung ê°¤ëŸ­ì‹œ ë²„ì¦ˆ`ëŠ” ë„ˆë¬´ broad â†’ timeout
4. **ì‹¤íŒ¨ ìºì‹œ ë¶€ì¬**: ê°™ì€ ì¿¼ë¦¬ ë°˜ë³µ ì¬ì‹œë„
5. **Playwright íƒ€ì„ì•„ì›ƒ**: budget ì†Œì§„ + frame detach

## í•´ê²°ì±… 5ê°€ì§€

### âœ… 1. Hard Mapping ì™„ì „ ë§¤ì¹­ ê°•ì œ (ì™„ë£Œ: hard_mapping_stage.py ìˆ˜ì •)

**ì´ë¯¸ ìˆ˜ì •ë¨:**
```python
# Stage 3ì—ì„œ ì™„ì „ ë§¤ì¹­ë§Œ ì§€ì›
if key == normalized_text:  # ë¶€ë¶„ í¬í•¨ âŒ
    return mapping[key]
```

### âœ… 2. Hard Mapping 1íšŒë§Œ ì‹¤í–‰ (ì‹ ê·œ êµ¬í˜„ í•„ìš”)

**êµ¬í˜„ ìœ„ì¹˜**: `src/utils/text/normalization/normalize.py`

Hard Mapping ê²°ê³¼ì—ëŠ” ë‹¤ì‹œ Hard Mappingì„ ì ìš©í•˜ì§€ ì•ŠìŒ

```python
class NormalizedResult:
    """ì •ê·œí™” ê²°ê³¼"""
    query: str
    is_hard_mapped: bool = False
    
def normalize_search_query(text: str) -> str:
    # Level 0: Hard Mapping
    hard_mapped = apply_hard_mapping_complete(text)
    if hard_mapped:
        # âœ… í”Œë˜ê·¸ë¥¼ í†µí•´ "ì´ë¯¸ Hard Mappingë¨"ì„ í‘œì‹œ
        # ì´í›„ ë‹¨ê³„ì—ì„œëŠ” ì¬ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        return hard_mapped
    
    # Level 1: UPCS (Hard Mappingì´ ì´ë¯¸ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ SKIP ê°€ëŠ¥)
    # Level 2: Legacy
```

### âœ… 3. ëª¨ë¸ ì„¸ëŒ€/ë“±ê¸‰ í† í° ë³´í˜¸ (ì‹ ê·œ ê·œì¹™ í•„ìš”)

**êµ¬í˜„ ìœ„ì¹˜**: `resources/hard_mapping.yaml`ì— ì¶”ê°€

```yaml
# ë³´í˜¸ í† í°: Hard Mapping ê²°ê³¼ê°€ ì´ í† í°ì„ ìƒìœ¼ë©´ ë¬´íš¨ ì²˜ë¦¬
protected_tokens:
  - r"\b\d+\b"           # ì„¸ëŒ€ ìˆ«ì (ë²„ì¦ˆ3, ì•„ì´í°17)
  - "í”„ë¡œ"
  - "pro"
  - "fe"
  - "max"
  - "ultra"
  - "plus"

# ê° ë§¤í•‘ ê·œì¹™ì— "ìµœì†Œ í† í°" ì¶”ê°€
mapping:
  "ê°¤ëŸ­ì‹œ ë²„ì¦ˆ": 
    result: "Samsung ê°¤ëŸ­ì‹œ ë²„ì¦ˆ"
    # âš ï¸ ì´ ë§¤í•‘ì€ ì…ë ¥ì—ì„œ ë‹¤ìŒ í† í°ì´ ìˆìœ¼ë©´ ë¬´íš¨:
    preserve_if_contains: ["2", "3", "í”„ë¡œ", "pro", "fe"]
    
  "ê°¤ëŸ­ì‹œ ë²„ì¦ˆ 2":
    result: "Samsung ê°¤ëŸ­ì‹œ ë²„ì¦ˆ 2"
    preserve_if_contains: ["í”„ë¡œ", "pro", "fe"]
    
  "ê°¤ëŸ­ì‹œ ë²„ì¦ˆ í”„ë¡œ":
    result: "Samsung ê°¤ëŸ­ì‹œ ë²„ì¦ˆ í”„ë¡œ"
```

### âœ… 4. ì‹¤íŒ¨ ìºì‹œ ê°•í™” (ë¶€ë¶„ ìˆ˜ì • í•„ìš”)

**ê¸°ì¡´ êµ¬ì¡° í™•ì¸:**
```python
# cache_service.pyì— ì´ë¯¸ ìˆìŒ
def get_negative(self, product_name: str) -> Optional[str]:
def set_negative(self, product_name: str, message: str) -> bool:
```

**ì¶”ê°€ í•„ìš”:**
- ì‹¤íŒ¨ íšŸìˆ˜ ì¹´ìš´íŒ…
- Në²ˆ ì—°ì† ì‹¤íŒ¨ ì‹œ Hard Skip
- ì‹¤íŒ¨ ì›ì¸ë³„ ë¶„ë¥˜ (timeout vs not_found vs validation_fail)

### âœ… 5. FastPath timeout ì¡°ê±´ë¶€ í™•ì¥ (ì‹ ê·œ ë¡œì§)

**êµ¬í˜„ ìœ„ì¹˜**: `src/crawlers/danawa/core/orchestrator.py`

```python
def is_broad_query(query: str) -> bool:
    """
    ê´‘ë²”ìœ„í•œ ê²€ìƒ‰ì–´ì¸ì§€ íŒë‹¨
    
    ì˜ˆ: "ê°¤ëŸ­ì‹œ ë²„ì¦ˆ", "ì•„ì´í°" â†’ ë§¤ìš° ë§ì€ ê²°ê³¼ ì˜ˆìƒ
    """
    BROAD_KEYWORDS = {
        "ê°¤ëŸ­ì‹œ", "ì•„ì´í°", "ì•„ì´íŒ¨ë“œ", "ë§¥ë¶",
        "ë¼ë©´", "ë…¸íŠ¸ë¶", "ì´ì–´í°", "ìŠ¤ë§ˆíŠ¸í°"
    }
    
    return len(query.split()) <= 2 and any(
        kw in query.lower() for kw in BROAD_KEYWORDS
    )

# FastPath íƒ€ì„ì•„ì›ƒ ì¡°ì •
if is_broad_query(normalized_query):
    timeout_ms = 10000  # 10ì´ˆë¡œ í™•ì¥
else:
    timeout_ms = 7800   # ê¸°ë³¸ 7.8ì´ˆ
```

---

## ì¦‰ì‹œ ì ìš© íŒ¨ì¹˜ (1,2ë²ˆ ìš°ì„ )

### íŒ¨ì¹˜ 1: Hard Mapping 1íšŒ ì‹¤í–‰ ê°•ì œ

**íŒŒì¼**: `src/utils/text/normalization/normalize.py`

```python
def normalize_search_query(text: str) -> str:
    """ì •ê·œí™” íŒŒì´í”„ë¼ì¸"""
    if not text:
        return ""
    
    # ğŸ”´ Level 0: Hard Mapping (1íšŒë§Œ ì‹¤í–‰)
    try:
        from .hard_mapping_stage import apply_hard_mapping_complete
        
        hard_mapped = apply_hard_mapping_complete(text)
        if hard_mapped:
            logger.info(f"[normalize] Level 0 Hard Mapping SUCCESS: '{text}' â†’ '{hard_mapped}'")
            # âœ… Hard Mapping ê²°ê³¼ëŠ” ë‹¤ì‹œ ì •ê·œí™”í•˜ì§€ ì•ŠìŒ
            # ë‹¤ìŒ ë‹¨ê³„(UPCS/Legacy)ë¡œ ì§„í–‰í•˜ì§€ ì•ŠìŒ
            return hard_mapped
    except Exception as e:
        logger.debug(f"[normalize] Level 0 Hard Mapping error: {e}")
    
    # ğŸŸ¡ Level 1: UPCS (Hard Mapping ì‹¤íŒ¨í•œ ê²½ìš°ë§Œ)
    try:
        from src.upcs.normalizer import normalize_query
        normalized = normalize_query(text, vendor="danawa")
        if normalized:
            logger.debug(f"[normalize] Level 1 UPCS normalization: '{text}' â†’ '{normalized}'")
            return str(normalized)
    except Exception as e:
        logger.debug(f"[normalize] Level 1 UPCS fallback: {e}")
    
    # ğŸŸ¢ Level 2: Legacy
    logger.debug(f"[normalize] Falling back to Level 2 legacy heuristics")
    return _normalize_search_query_legacy(text)
```

### íŒ¨ì¹˜ 2: Hard Mapping ê²°ê³¼ ê²€ì¦ ê°•í™”

**íŒŒì¼**: `src/utils/text/normalization/hard_mapping_stage.py`

```python
@staticmethod
def stage_4_validate_result(
    original_text: str,
    normalized_text: str,
    mapped_result: Optional[str]
) -> bool:
    """Stage 4: ê²°ê³¼ ê²€ì¦ (í”„ë¡œë•ì…˜ ì•ˆì „ì¥ì¹˜)"""
    
    if not mapped_result:
        return False
    
    # 1ï¸âƒ£ ë¸Œëœë“œ ëª…ì‹œ í™•ì¸ (ê¸°ì¡´)
    brands = {"apple", "samsung", "lg", "dell", ...}
    if not any(brand in mapped_result.lower() for brand in brands):
        logger.warning(f"[Stage 4] Missing brand: {mapped_result}")
        return False
    
    # 2ï¸âƒ£ ìƒˆë¡œìš´ ê²€ì¦: ì¤‘ìš” í† í° ë³´ì¡´ í™•ì¸
    # ì…ë ¥ì— ìˆë˜ ì¤‘ìš” ì •ë³´ê°€ ê²°ê³¼ì—ë„ ìˆëŠ”ì§€ í™•ì¸
    
    input_lower = original_text.lower()
    result_lower = mapped_result.lower()
    
    # ìˆ«ì(ì„¸ëŒ€)ê°€ ì…ë ¥ì— ìˆì—ˆëŠ”ë° ê²°ê³¼ì— ì—†ìœ¼ë©´ ê²½ê³ 
    input_numbers = set(re.findall(r'\d+', input_lower))
    result_numbers = set(re.findall(r'\d+', result_lower))
    
    if input_numbers and not (input_numbers & result_numbers):
        logger.warning(f"[Stage 4] Number token lost: {input_numbers}")
        # âš ï¸ ìˆ«ì ì†ì‹¤ì€ ì¼ë¶€ í—ˆìš© (Pro ê°™ì€ ê²½ìš°ë„ ìˆìœ¼ë‹ˆ)
        # í•˜ì§€ë§Œ ë¡œê·¸ëŠ” ë‚¨ê²¨ì•¼ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥
    
    # "í”„ë¡œ", "ë§¥ìŠ¤", "ìš¸íŠ¸ë¼" ê°™ì€ ë“±ê¸‰ ì •ë³´ë„ í™•ì¸
    grade_keywords = ["í”„ë¡œ", "pro", "max", "ultra", "fe", "plus"]
    if any(kw in input_lower for kw in grade_keywords):
        if not any(kw in result_lower for kw in grade_keywords):
            logger.warning(f"[Stage 4] Grade token lost: {grade_keywords}")
            return False  # ë“±ê¸‰ ì •ë³´ ì†ì‹¤ì€ ê±°ì ˆ
    
    return True
```

---

## ëª¨ë‹ˆí„°ë§ & ì•ŒëŒ ì¶”ê°€ (ì„ íƒ)

### ì¶”ê°€ ë¡œê¹… í¬ì¸íŠ¸

```python
logger.info(f"[QUALITY] Hard Mapping: '{original}' â†’ '{result}' (info_loss={has_info_loss})")
logger.warning(f"[ALERT] Query too broad: '{query}' (expected_results=many, timeout_risk=high)")
logger.error(f"[CRITICAL] Repeated failure: query='{query}', attempts=3, strategy=skip_crawl")
```

---

## ìµœì¢… ê²€ì¦: ë¡œê·¸ ë¹„êµ

### Before (âŒ ë¬¸ì œ)
```
[Stage 3] Hard Mapping matched:
'ì‚¼ì„±ì „ì ê°¤ëŸ­ì‹œ ë²„ì¦ˆ3 í”„ë¡œ ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í°'
â†’ 'Samsung ê°¤ëŸ­ì‹œ ë²„ì¦ˆ'
```

### After (âœ… í•´ê²°)
```
[Stage 3] Hard Mapping exact match? 
'samsung ê°¤ëŸ­ì‹œ ë²„ì¦ˆ3 í”„ë¡œ'
== 'samsung ê°¤ëŸ­ì‹œ ë²„ì¦ˆ'? NO
â†’ None (Synonym/Fallbackìœ¼ë¡œ)
```

---

## ë‹¤ìŒ ì•¡ì…˜

1. **íŒ¨ì¹˜ 1,2 ì¦‰ì‹œ ì ìš©** (hard_mapping_stage.py + normalize.py ìˆ˜ì •)
2. **í…ŒìŠ¤íŠ¸**: "ì‚¼ì„±ì „ì ê°¤ëŸ­ì‹œ ë²„ì¦ˆ3 í”„ë¡œ" ì¬ì‹œë„
3. **íŒ¨ì¹˜ 3,4,5 ì ìš©** (YAML + timeout + failure_cache)
4. **ëª¨ë‹ˆí„°ë§**: ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤íŒ¨ íŒ¨í„´ ì¶”ì 

