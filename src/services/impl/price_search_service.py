"""ê°€ê²© ê²€ìƒ‰ ì„œë¹„ìŠ¤ - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""
import asyncio
from typing import Optional, Dict, Any
from sqlalchemy.orm import Session

from src.services.impl.cache_service import CacheService
from src.crawlers.danawa import DanawaCrawler
from src.repositories.impl.search_log_repository import SearchLogRepository
from src.repositories.impl.search_failure_repository import SearchFailureRepository
from src.repositories.impl.price_cache_repository import PriceCacheRepository
from src.utils.search import DanawaSearchHelper
from src.core.logging import logger
from src.core.exceptions import ProductNotFoundException, CrawlerException
from src.core.config import settings


class PriceSearchService:
    """
    ê°€ê²© ê²€ìƒ‰ ì„œë¹„ìŠ¤ - SRP: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¡°ìœ¨ë§Œ ë‹´ë‹¹
    
    - ìºì‹œ ì¡°íšŒëŠ” CacheService
    - í¬ë¡¤ë§ì€ DanawaCrawler
    - DB ì €ì¥ì€ SearchLogRepository
    """
    
    def __init__(self, cache_service: CacheService, db_session: Optional[Session] = None):
        self.cache_service = cache_service
        self.db_session = db_session
        self.search_helper = DanawaSearchHelper()
    
    async def search_price(
        self,
        product_name: str,
        current_price: Optional[int] = None,
        product_code: Optional[str] = None
    ) -> Dict:
        """
        ìµœì €ê°€ ê²€ìƒ‰ (Cache-First ì „ëµ)
        
        1. Redis ìºì‹œ í™•ì¸ (ì •ê·œí™”ëœ ìƒí’ˆëª… ê¸°ì¤€)
        2. ìºì‹œ ë¯¸ìŠ¤ ì‹œ í¬ë¡¤ë§
        3. ê²°ê³¼ ìºì‹± ë° ë°˜í™˜
        
        Args:
            product_name: ê²€ìƒ‰í•  ìƒí’ˆëª…
            current_price: ì‚¬ìš©ìê°€ ë³´ê³  ìˆëŠ” í˜„ì¬ ê°€ê²©
            
        Returns:
            {
                "lowest_price": int,
                "link": str,
                "is_cheaper": bool,
                "price_diff": int,
                "status": str,  # HIT, MISS, FAIL
                "message": str
            }
        """
        # ê²€ìƒ‰ì–´ë¥¼ ë¨¼ì € ì •ê·œí™”í•˜ì—¬ ìºì‹œ í‚¤ì™€ ê²€ìƒ‰ ì¼ê´€ì„± ìœ ì§€
        from src.utils.text import clean_product_name, normalize_search_query
        
        # ì •ê·œí™”ëœ ìƒí’ˆëª…ìœ¼ë¡œ ìºì‹œ í‚¤ ìƒì„±
        normalized_name = normalize_search_query(product_name) or clean_product_name(product_name)
        search_key = clean_product_name(normalized_name)
        
        logger.info(f"Search request: {product_name}")
        logger.info(f"Normalized query for search: {normalized_name}")
        logger.debug(f"Cache key: {search_key}")

        # 1. ìºì‹œ í™•ì¸
        cached = self.cache_service.get(search_key)
        
        if cached:
            logger.info(f"Cache hit for key: {search_key}")
            return self._build_response(
                result=cached.model_dump(),
                current_price=current_price,
                status="HIT",
                message="ìºì‹œì—ì„œ ë°œê²¬í–ˆìŠµë‹ˆë‹¤."
            )

        # 1-1. ë¶€ì • ìºì‹œ í™•ì¸ (ìµœê·¼ ë¯¸ë°œê²¬ì´ë©´ í¬ë¡¤ë§ ì¬ì‹œë„ ì–µì œ)
        negative_message = self.cache_service.get_negative(search_key)
        if negative_message:
            logger.info(f"Negative cache hit for: {search_key}")
            return self._build_error_response(negative_message)

        # 1-2. DB ì˜ì† ìºì‹œ í™•ì¸ (Redis ë¯¸ìŠ¤/ë¶€ì • ìºì‹œ ì—†ìŒ)
        # DBì— ì €ì¥ëœ ê¹¨ë—í•œ product_nameì„ ì¬ì‚¬ìš©í•˜ì—¬ ë§¤ë²ˆ ì •ê·œí™” ì‘ì—…ì„ í”¼í•¨
        if self.db_session is not None:
            db_cached = PriceCacheRepository(self.db_session).get_fresh(
                cache_key=search_key,
                max_age_seconds=int(settings.cache_ttl),
            )
            if db_cached:
                # Redisì—ë„ ì¬ì ì¬í•˜ì—¬ ì´í›„ ìš”ì²­ì€ ë” ë¹ ë¥´ê²Œ
                try:
                    self.cache_service.set(search_key, db_cached)
                except Exception:
                    pass
                logger.info(f"DB cache hit for key: {search_key}, product_name={db_cached.get('product_name', 'N/A')}")
                return self._build_response(
                    result=db_cached,
                    current_price=current_price,
                    status="HIT",
                    message="DB ìºì‹œì—ì„œ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.",
                )
        
        # 1-3. ğŸ”´ Hard Skip í™•ì¸ (3íšŒ ì´ìƒ ì—°ì† ì‹¤íŒ¨ â†’ ì¦‰ì‹œ ê±°ì ˆ)
        if self.cache_service.should_hard_skip(search_key, max_failures=3):
            msg = "ì´ ìƒí’ˆì€ ë°˜ë³µì ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ìµœê·¼ 3íšŒ ì‹¤íŒ¨)"
            logger.warning(f"Hard skip activated for: {search_key}")
            return self._build_error_response(msg)
        logger.info(f"Cache miss, crawling for: {search_key}")
        
        try:
            async with DanawaCrawler() as crawler:
                # âœ… ìºì‹œì™€ í¬ë¡¤ë§ ëª¨ë‘ ì •ê·œí™”ëœ ì¿¼ë¦¬ ì‚¬ìš©
                # ì´ì „: ì›ë³¸ product_nameì„ í¬ë¡¤ëŸ¬ì— ì „ë‹¬ â†’ ì¤‘ë³µ ì •ê·œí™” + ì‹ í˜¸ ì†ì‹¤
                # ê°œì„ : ì •ê·œí™”ëœ normalized_nameì„ ì§ì ‘ ì „ë‹¬
                result = await crawler.search_lowest_price(normalized_name, product_code=product_code)
            
            if not result:
                msg = "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                self.cache_service.set_negative(search_key, msg)
                return self._build_error_response(msg)
            
            # 3. ìºì‹±
            self.cache_service.set(search_key, result)
            # ğŸŸ¢ ì„±ê³µ â†’ ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
            self.cache_service.reset_failure_count(search_key)

            # 3-1. DBì—ë„ ì˜ì† ìºì‹œ ì €ì¥ (ì„ íƒ)
            # DBì— ì €ì¥ëœ ê¹¨ë—í•œ product_nameì„ ë‹¤ìŒ ìš”ì²­ì—ì„œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
            if self.db_session is not None:
                try:
                    logger.debug(f"Saving to DB cache: {search_key}, product_name={result.get('product_name', 'N/A')}")
                    PriceCacheRepository(self.db_session).upsert(search_key, result)
                except Exception as e:
                    # DB ìºì‹œ ì‹¤íŒ¨ëŠ” ê¸°ëŠ¥ì  ì‹¤íŒ¨ê°€ ì•„ë‹ˆë¯€ë¡œ ë¬´ì‹œ
                    logger.warning(f"DB cache write failed: {e}")
                    pass
            
            return self._build_response(
                result=result,
                current_price=current_price,
                status="MISS",
                message="ë‹¤ë‚˜ì™€ì—ì„œ ìƒˆë¡œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
            )
        
        except asyncio.TimeoutError:
            msg = "ìš”ì²­ ì‹œê°„ ì´ˆê³¼"
            logger.warning(f"Search timeout for: {product_name}")
            self.cache_service.set_negative(search_key, msg)
            # ğŸ”´ ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ì¦ê°€
            fail_count = self.cache_service.increment_failure_count(search_key)
            self._record_search_failure(
                product_name=product_name,
                normalized_name=normalized_name,
                error_message=f"{msg} (fail_count={fail_count})",
            )
            return self._build_error_response(msg)

        except ProductNotFoundException as e:
            logger.warning(f"Product not found: {e}")
            msg = str(e)
            self.cache_service.set_negative(search_key, msg)
            # ğŸ”´ ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ì¦ê°€
            fail_count = self.cache_service.increment_failure_count(search_key)
            
            # ì‹¤íŒ¨ ê¸°ë¡ ì €ì¥ (í•™ìŠµìš©)
            self._record_search_failure(
                product_name=product_name,
                normalized_name=normalized_name,
                error_message=f"{msg} (fail_count={fail_count})"
            )
            
            return self._build_error_response(msg)
        
        except CrawlerException as e:
            logger.error(f"Crawler error: {e}")
            # ğŸ”´ ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ì¦ê°€
            fail_count = self.cache_service.increment_failure_count(search_key)
            
            # ì‹¤íŒ¨ ê¸°ë¡ ì €ì¥
            self._record_search_failure(
                product_name=product_name,
                normalized_name=normalized_name,
                error_message=f"Crawler error: {str(e)} (fail_count={fail_count})"
            )
            
            return self._build_error_response("í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        except Exception as e:
            logger.error(f"Unexpected error in search_price: {e}")
            # ğŸ”´ ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ì¦ê°€
            fail_count = self.cache_service.increment_failure_count(search_key)
            
            # ì‹¤íŒ¨ ê¸°ë¡ ì €ì¥
            self._record_search_failure(
                product_name=product_name,
                normalized_name=normalized_name,
                error_message=f"Unexpected error: {str(e)} (fail_count={fail_count})"
            )
            
            return self._build_error_response("ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    def _build_response(
        self,
        result: Dict[str, Any],
        current_price: Optional[int],
        status: str,
        message: str
    ) -> Dict:
        """ì„±ê³µ ì‘ë‹µ ìƒì„±"""
        product_name = result.get("product_name", "")
        lowest_price = result.get("lowest_price", 0)
        link = result.get("link", "")
        mall = result.get("mall")
        free_shipping = result.get("free_shipping")
        top_prices = result.get("top_prices")
        price_trend = result.get("price_trend")

        is_cheaper = False
        price_diff = 0
        
        if current_price is not None:
            is_cheaper = lowest_price < current_price
            price_diff = lowest_price - current_price
        
        return {
            "product_name": product_name,
            "lowest_price": lowest_price,
            "link": link,
            "mall": mall,
            "free_shipping": free_shipping,
            "top_prices": top_prices,
            "price_trend": price_trend,
            "is_cheaper": is_cheaper,
            "price_diff": price_diff,
            "status": status,
            "message": message
        }
    
    def _build_error_response(self, message: str) -> Dict:
        """ì‹¤íŒ¨ ì‘ë‹µ ìƒì„±"""
        return {
            "product_name": "",
            "lowest_price": 0,
            "link": "",
            "mall": None,
            "free_shipping": None,
            "top_prices": None,
            "price_trend": None,
            "is_cheaper": False,
            "price_diff": 0,
            "status": "FAIL",
            "message": message
        }
    
    async def log_search(
        self,
        db: Session,
        query_name: str,
        origin_price: Optional[int],
        found_price: Optional[int],
        status: str
    ) -> None:
        """
        ê²€ìƒ‰ ë¡œê·¸ ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)
        
        Args:
            db: DB ì„¸ì…˜
            query_name: ê²€ìƒ‰í•œ ìƒí’ˆëª…
            origin_price: ì‚¬ìš©ìê°€ ë³´ë˜ ì›ë˜ ê°€ê²©
            found_price: ì°¾ì•„ë‚¸ ìµœì €ê°€
            status: HIT, MISS, FAIL
        """
        try:
            repo = SearchLogRepository(db)
            repo.create(
                query_name=query_name,
                origin_price=origin_price,
                found_price=found_price,
                status=status
            )
        except Exception as e:
            logger.error(f"Failed to log search: {e}")
    
    def _record_search_failure(
        self,
        product_name: str,
        normalized_name: str,
        error_message: str,
        attempted_count: int = 1
    ) -> None:
        """
        ê²€ìƒ‰ ì‹¤íŒ¨ ê¸°ë¡ (í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘)
        
        Args:
            product_name: ì›ë³¸ ìƒí’ˆëª…
            normalized_name: ì •ê·œí™”ëœ ìƒí’ˆëª…
            error_message: ì—ëŸ¬ ë©”ì‹œì§€
            attempted_count: ì‹œë„ íšŸìˆ˜
        """
        if not self.db_session:
            logger.debug("DB session not available for failure logging")
            return
        
        try:
            # ì¹´í…Œê³ ë¦¬ ë° ë¸Œëœë“œ/ëª¨ë¸ ì¶”ì¶œ
            category = self.search_helper.detect_category(product_name)
            brand, model = self.search_helper.extract_brand_and_model(product_name)
            
            # ì‹œë„í•œ í›„ë³´ ìƒì„±
            candidates = self.search_helper.generate_search_candidates(product_name)
            
            # ì‹¤íŒ¨ ê¸°ë¡ ì €ì¥
            SearchFailureRepository.record_failure(
                db=self.db_session,
                original_query=product_name,
                normalized_query=normalized_name,
                candidates=candidates,
                attempted_count=attempted_count,
                error_message=error_message,
                category_detected=category,
                brand=brand,
                model=model
            )
            
            logger.info(f"Recorded search failure for: {product_name}")
        
        except Exception as e:
            logger.error(f"Failed to record search failure: {e}")

