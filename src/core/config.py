"""ì„¤ì • ê´€ë¦¬ - í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ê²€ì¦"""
from typing import Optional
from pydantic_settings import BaseSettings
from pydantic import field_validator


class Settings(BaseSettings):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •"""
    
    # ë°ì´í„°ë² ì´ìŠ¤
    database_url: str = ""
    
    # Redis
    redis_url: str = ""
    cache_ttl: int = 21600  # 6ì‹œê°„
    
    # í¬ë¡¤ëŸ¬
    crawler_timeout: int = 30000
    crawler_user_agent: str = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    crawler_max_retries: int = 3
    crawler_rate_limit_min: float = 0.5
    crawler_rate_limit_max: float = 1.5

    # í•˜ì´ë¸Œë¦¬ë“œ(HTTP Fast Path â†’ Playwright Fallback) ì„±ëŠ¥ ì„¤ì •
    # NOTE: ê¸°ë³¸ê°’ì€ 'ì•ˆì •ì„± ìš°ì„ 'ìœ¼ë¡œ ì—¬ìœ ìžˆê²Œ ì„¤ì •í•©ë‹ˆë‹¤.
    # - crawler_http_timeout_ms: HTTP fast path ì „ì²´ ì˜ˆì‚°
    # - crawler_http_request_timeout_ms: HTTP ë‹¨ì¼ ìš”ì²­ íƒ€ìž„ì•„ì›ƒ(ê²€ìƒ‰ íŽ˜ì´ì§€ ë“±)
    # - crawler_http_product_timeout_ms: HTTP ìƒí’ˆ ìƒì„¸ íŽ˜ì´ì§€ íƒ€ìž„ì•„ì›ƒ
    crawler_total_budget_ms: int = 12000
    crawler_http_timeout_ms: int = 9000
    crawler_http_request_timeout_ms: int = 5000
    crawler_http_product_timeout_ms: int = 7000
    crawler_http_impersonate: str = "chrome110"
    crawler_http_max_clients: int = 20
    crawler_enable_price_trend: bool = False

    # Playwright ë™ì‹œì„± ì œí•œ(ì„œë²„ í„°ì§ ë°©ì§€)
    crawler_browser_concurrency: int = 2

    # ì•± ì‹œìž‘ ì‹œ Playwright ë¸Œë¼ìš°ì €ë¥¼ ë¯¸ë¦¬ ë„ìš¸ì§€ ì—¬ë¶€
    # ê¸°ë³¸ê°’ì€ False: ìš”ì²­ì—ì„œ HTTP Fast Pathê°€ ì‹¤íŒ¨í•  ë•Œë§Œ lazy-launch
    crawler_playwright_warmup: bool = False

    # Fast Path íšŒë¡œì°¨ë‹¨(CB): ì—°ì† ì‹¤íŒ¨ ì‹œ ìž ê¹ Fast Path ìŠ¤í‚µ
    crawler_fastpath_fail_threshold: int = 5
    crawler_fastpath_open_seconds: int = 60

    # Fast Path HTML ê²€ì¦(ìºì‹œ ì˜¤ì—¼ ë°©ì§€)
    crawler_fastpath_min_html_length: int = 5000

    # Fast Path íŒŒì‹±ì—ì„œ ë„ˆë¬´ ì‹¼ ê°€ê²©(ì•¡ì„¸ì„œë¦¬/ì˜¤íƒ) ë°°ì œìš© í•˜í•œ
    # 0ì´ë©´ ë¹„í™œì„±í™”
    crawler_min_price_threshold: int = 0
    
    # API
    api_title: str = "ìµœì €ê°€ íƒì§€ ì„œë¹„ìŠ¤"
    api_version: str = "1.0.0"
    api_description: str = "Cache-First ì „ëžµìœ¼ë¡œ ìµœì €ê°€ë¥¼ ë¹ ë¥´ê²Œ ê²€ìƒ‰í•©ë‹ˆë‹¤."

    # FE(ë¸Œë¼ìš°ì €) íƒ€ìž„ì•„ì›ƒë³´ë‹¤ ì§§ê²Œ ì„œë²„ì—ì„œ í•˜ë“œ ìº¡ì„ ê±¸ì–´
    # ìš”ì²­ì´ ë§¤ë‹¬ë¦° ì±„ë¡œ í´ë¼ì´ì–¸íŠ¸ì—ì„œ íƒ€ìž„ì•„ì›ƒë˜ëŠ” ìƒí™©ì„ ì¤„ìž…ë‹ˆë‹¤.
    # ðŸ”´ ê¸°ê°€ì°¨ë“œ ìˆ˜ì •: Playwright í´ë°± ê³ ë ¤í•˜ì—¬ 20ì´ˆë¡œ ìƒí–¥ (ê¸°ì¡´ 14ì´ˆ)
    api_price_search_timeout_s: float = 20.0
    
    # ë¡œê¹…
    log_level: str = "INFO"
    
    @field_validator("cache_ttl")
    @classmethod
    def validate_cache_ttl(cls, v: int) -> int:
        if v <= 0:
            raise ValueError("cache_ttl must be positive")
        return v
    
    @field_validator("crawler_timeout")
    @classmethod
    def validate_crawler_timeout(cls, v: int) -> int:
        if v <= 0:
            raise ValueError("crawler_timeout must be positive")
        return v

    @field_validator("crawler_min_price_threshold")
    @classmethod
    def validate_crawler_min_price_threshold(cls, v: int) -> int:
        if v < 0:
            raise ValueError("crawler_min_price_threshold must be >= 0")
        return v

    @field_validator("crawler_total_budget_ms", "crawler_http_timeout_ms")
    @classmethod
    def validate_crawler_budgets(cls, v: int) -> int:
        if v <= 0:
            raise ValueError("crawler budgets must be positive")
        return v

    @field_validator("crawler_browser_concurrency")
    @classmethod
    def validate_crawler_concurrency(cls, v: int) -> int:
        if v <= 0:
            raise ValueError("crawler_browser_concurrency must be positive")
        return v

    @field_validator("database_url", "redis_url")
    @classmethod
    def validate_required_urls(cls, v: str) -> str:
        if not v:
            raise ValueError("database_url and redis_url must not be empty")
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False


settings = Settings()
