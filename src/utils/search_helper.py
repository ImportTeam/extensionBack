"""ë‹¤ë‚˜ì™€ ê²€ìƒ‰ ìë™ì™„ì„± í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ ì •ê·œí™”"""
import re
from typing import Optional
from src.core.logging import logger
from src.utils.resource_loader import load_search_substitutions, load_search_categories


class DanawaSearchHelper:
    """ë‹¤ë‚˜ì™€ ê²€ìƒ‰ ìµœì í™” í—¬í¼ - ë‹¤ë‚˜ì™€ ìë™ì™„ì„±ê³¼ ê³„ì¸µì  í´ë°± ê²€ìƒ‰ í™œìš©"""
    
    def __init__(self):
        # ë¦¬ì†ŒìŠ¤ì—ì„œ ì¹´í…Œê³ ë¦¬ ì„¤ì • ë¡œë“œ
        categories = load_search_categories()
        
        # ì¹´í…Œê³ ë¦¬ë³„ í•µì‹¬ í† í°
        self.category_keywords = {
            cat: set(info.get("keywords", [])) 
            for cat, info in categories.items()
        }
        
        # ì¹´í…Œê³ ë¦¬ ê°ì§€ í‚¤ì›Œë“œ
        self.category_patterns = {
            cat: info.get("pattern", "") 
            for cat, info in categories.items()
        }
    
    def detect_category(self, product_name: str) -> Optional[str]:
        """ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        for category, pattern in self.category_patterns.items():
            if re.search(pattern, product_name, re.IGNORECASE):
                return category
        return None
    
    def extract_brand_and_model(self, product_name: str) -> tuple[str, str]:
        """ë¸Œëœë“œì™€ ëª¨ë¸ëª… ì¶”ì¶œ (ì—°ë„ ë“± ë…¸ì´ì¦ˆ ê±´ë„ˆë›°ê¸°)"""
        from src.utils.text import clean_product_name, split_kr_en_boundary
        
        cleaned = clean_product_name(product_name)
        normalized = split_kr_en_boundary(cleaned)
        tokens = normalized.split()
        
        if len(tokens) == 0:
            return "", ""
        
        # ì²« ë²ˆì§¸ í† í° = ë¸Œëœë“œ (Apple, Samsung, LG ë“±)
        brand = tokens[0]
        
        # ì—°ë„ í† í° ê±´ë„ˆë›°ê¸° (ì˜ˆ: Apple 2025 ë§¥ë¶ -> brand=Apple, model_start=ë§¥ë¶)
        start_idx = 1
        if len(tokens) > 1 and re.match(r"^(19|20)\d{2}$", tokens[1]):
            start_idx = 2
        
        # 2~3ë²ˆì§¸ í† í° = ëª¨ë¸ëª… (ì—ì–´íŒŸ, ê°¤ëŸ­ì‹œë²„ì¦ˆ ë“±)
        model = " ".join(tokens[start_idx:start_idx+3]) if len(tokens) > start_idx else ""
        
        return brand, model
    
    def generate_search_candidates(self, product_name: str) -> list[str]:
        """ê³„ì¸µì  í´ë°± ê²€ìƒ‰ í›„ë³´ ìƒì„± (íš¨ìœ¨ì )
        
        ìš°ì„ ìˆœìœ„:
        1. ì—°ë„ ì œê±° ë²„ì „ (ì„±ê³µë¥  ìµœê³ )
        2. ì •ê·œí™”ëœ ë²„ì „
        3. ë¸Œëœë“œ + ëª¨ë¸ (ì¹©ì…‹ í¬í•¨)
        4. ëª¨ë¸ëª…ë§Œ
        5. ë¸Œëœë“œë§Œ
        """
        from src.utils.text import clean_product_name, normalize_search_query
        
        candidates = []
        seen = set()
        
        def add_candidate(cand: str, reason: str = ""):
            if not cand: return
            cand = cand.strip()
            if cand and cand.lower() not in seen:
                seen.add(cand.lower())
                candidates.append(cand)
                if reason:
                    logger.debug(f"[SearchCandidates] Added: '{cand}' ({reason})")

        # ğŸ”´ í•µì‹¬: ì—°ë„ ì œê±°ê°€ ê°€ì¥ ë¨¼ì €! (ë‹¤ë‚˜ì™€ ê²€ìƒ‰ì—”ì§„ì´ ì—°ë„ ì¡°ê±´ì—ì„œ ì‹¤íŒ¨)
        no_year = re.sub(r"\b(19|20)\d{2}\b", " ", product_name)
        no_year = re.sub(r"\s+", " ", no_year).strip()
        if no_year and no_year.lower() != product_name.lower():
            add_candidate(no_year, reason="ì—°ë„ ì œê±° ë²„ì „")
        
        # ì •ê·œí™”ëœ ì „ì²´
        normalized = normalize_search_query(product_name)
        add_candidate(normalized, reason="ì •ê·œí™” ë²„ì „")
        
        # ë¸Œëœë“œ + ëª¨ë¸ëª… ì¶”ì¶œ (ì—°ë„ ì œì™¸)
        brand, model = self.extract_brand_and_model(product_name)
        if brand and model:
            # ëª¨ë¸ì—ì„œ ê³¼ë„í•œ ìŠ¤í™ ì œê±°
            model_cleaned = re.sub(r'\s*\d+(\.\d+)?[GgTt][Bb]\s*', '', model).strip()
            add_candidate(f"{brand} {model_cleaned}", reason="ë¸Œëœë“œ+ëª¨ë¸ëª…")
            
            # ì¹©ì…‹ ì •ë³´ê°€ ìˆë‹¤ë©´ í¬í•¨ (M1, M2, M3, M4 ë“±)
            m_chip = re.search(r"(?i)M\s*\d+", product_name)
            if m_chip:
                add_candidate(f"{brand} {model_cleaned} {m_chip.group()}".strip(), reason="ë¸Œëœë“œ+ëª¨ë¸+ì¹©ì…‹")
        
        # ëª¨ë¸ëª…ë§Œ (ì²˜ìŒ 2-3ê°œ ë‹¨ì–´)
        if model:
            model_tokens = model.split()[:3]
            if model_tokens:
                add_candidate(" ".join(model_tokens), reason="ëª¨ë¸ëª…ë§Œ")
        
        # ë¸Œëœë“œë§Œ
        if brand:
            add_candidate(brand, reason="ë¸Œëœë“œë§Œ")
        
        # ëŒ€ì²´ ê²€ìƒ‰ì–´ (ë§¥ë¶ -> MacBook ë“±)
        substitutions = load_search_substitutions()
        product_lower = product_name.lower()
        for kr_term, en_terms in substitutions.items():
            if kr_term in product_name or kr_term.lower() in product_lower:
                for en in en_terms:
                    add_candidate(en, reason=f"ëŒ€ì²´ê²€ìƒ‰ì–´ ({kr_term}â†’{en})")
        
        logger.info(f"[SearchCandidates] Generated {len(candidates)} candidates for '{product_name}': {candidates}")
        return candidates if candidates else [clean_product_name(product_name)]
    
    def get_smart_search_query(self, product_name: str) -> str:
        """ê°€ì¥ íš¨ìœ¨ì ì¸ ê²€ìƒ‰ì–´ ë°˜í™˜ (ìš°ì„ ìˆœìœ„: ì •ê·œí™” â†’ ë¸Œëœë“œ+ëª¨ë¸ â†’ ëª¨ë¸)"""
        from src.utils.text import normalize_search_query
        
        # ì¹´í…Œê³ ë¦¬ ê°ì§€
        category = self.detect_category(product_name)
        logger.debug(f"Detected category: {category}")
        
        # ì •ê·œí™”ëœ ê²€ìƒ‰ì–´ ì‚¬ìš© (ì´ë¯¸ ì¶©ë¶„í•¨)
        normalized = normalize_search_query(product_name)
        if normalized and len(normalized.split()) >= 2:
            return normalized
        
        # Fallback: ë¸Œëœë“œ + ëª¨ë¸
        brand, model = self.extract_brand_and_model(product_name)
        if brand and model:
            return f"{brand} {model.split()[0] if model.split() else ''}".strip()
        
        # ìµœí›„ì˜ ìˆ˜ë‹¨: ì›ë³¸
        return product_name
